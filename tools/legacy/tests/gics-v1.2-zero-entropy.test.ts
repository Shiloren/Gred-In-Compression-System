
import assert from 'node:assert'; // Keep assert or use expect
import { SeededRNG } from '../bench/scripts/rng.js';
import { generateVolatileInt } from '../bench/scripts/datasets.js';
import { GICSv2Encoder } from '../src/gics/encode.js';

describe('GICS Zero-Entropy Verification', () => {

    it('SeededRNG should be deterministic', () => {
        const rng1 = new SeededRNG(12345);
        const seq1 = [rng1.next(), rng1.next(), rng1.next()];

        const rng2 = new SeededRNG(12345);
        const seq2 = [rng2.next(), rng2.next(), rng2.next()];

        assert.deepStrictEqual(seq1, seq2, 'RNG sequence must be identical for same seed');

        const rng3 = new SeededRNG(999);
        const val3 = rng3.next();
        assert.notStrictEqual(seq1[0], val3, 'Different seed must produce different value');
    });

    it('HighVolatility Generation should be deterministic', () => {
        const ds1 = generateVolatileInt(1000, 55555);
        const ds2 = generateVolatileInt(1000, 55555);

        // Assert Metadata
        assert.strictEqual(ds1.checksum, ds2.checksum, 'Dataset checksums must match for same seed');
        assert.strictEqual(ds1.data.length, ds2.data.length);

        // Assert Content
        assert.deepStrictEqual(ds1.data, ds2.data, 'Dataset content must be DeepStrictEqual');

        // Different seed
        const ds3 = generateVolatileInt(1000, 11111);
        assert.notStrictEqual(ds1.checksum, ds3.checksum, 'Different seed => different checksum');
    });

    it('A/B Fairness: Identical Dataset Hash for Context Modes', async () => {
        // Enforce same seed
        const seed = 777;
        const dsOriginal = generateVolatileInt(100, seed);

        // Simulate Harness Loop check
        // Mode OFF
        process.env.GICS_CONTEXT_MODE = 'off';
        // (Encoder usage doesn't change dataset, but we verify we are using same dataset object/hash)

        // Mode ON
        process.env.GICS_CONTEXT_MODE = 'on';

        // The requirement is that "OFF and ON runs for the same baseVariant use identical dataset_hash".
        // In harness this is enforced by reusing the dataset object or regenerating with same seed.
        // Here we verify that our generation function is stable enough to yield same hash if called twice (which we did above).

        // We also verify that GICSv2Encoder doesn't mutate dataset (it shouldn't).
        const enc = new GICSv2Encoder();

        const snapshot = { timestamp: 0, items: new Map() };
        await enc.addSnapshot(snapshot);
        await enc.flush();
        await enc.finalize();

        // Verify Integrity
        const dsAfter = generateVolatileInt(100, seed);
        assert.strictEqual(dsOriginal.checksum, dsAfter.checksum, 'Dataset generation must remain stable');
    });
});
